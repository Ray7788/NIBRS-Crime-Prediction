{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map column variables to Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Data/IL-2020/NIBRS_ARRESTEE.csv\n",
      "File: Data/IL-2020/NIBRS_ARRESTEE.csv's col names have been transferred to UpperCase!\n",
      "Processing: Data/IL-2021/NIBRS_ARRESTEE.csv\n",
      "File: Data/IL-2021/NIBRS_ARRESTEE.csv's col names have been transferred to UpperCase!\n",
      "Processing: Data/IL-2022/NIBRS_ARRESTEE.csv\n",
      "File: Data/IL-2022/NIBRS_ARRESTEE.csv's col names have been transferred to UpperCase!\n",
      "Processing: Data/IL-2023/NIBRS_ARRESTEE.csv\n",
      "File: Data/IL-2023/NIBRS_ARRESTEE.csv's col names have been transferred to UpperCase!\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "years = ['2020', '2021', '2022', '2023']\n",
    "base_path = \"Data\"\n",
    "file_name = \"NIBRS_ARRESTEE.csv\"\n",
    "# file_name = \"NIBRS_incident.csv\"\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    folder_path = os.path.join(base_path, f\"IL-{year}\")\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File: {file_path} does not exist!\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing: {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Transfer Column Name To UpperCase\n",
    "    new_columns = [col.upper() for col in df.columns]\n",
    "\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    # Rewrite Origin File\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"File: {file_path}'s col names have been transferred to UpperCase!\")\n",
    "\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add variables from different dataframes(csv files) to a single dataframe\n",
    "\n",
    "code for deleting redundant and useless columns for NIBRS test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read CSV file from Earn's merged dataset\n",
    "df = pd.read_csv(\"merged_2023.csv\")\n",
    "\n",
    "# 2. Define columns to drop (including duplicate columns and user-specified columns)\n",
    "columns_to_drop = [\n",
    "    # Duplicate columns (SQL's fault)\n",
    "    \"incident_id-2\", \"incident_id-3\",  # duplicate incident_id\n",
    "    \"arrest_type_id-2\",                # duplicate arrest_type_id\n",
    "    \"offense_code-2\", \"offense_code-3\",# duplicate offense_code\n",
    "    \"location_id-2\",                   # duplicate location_id\n",
    "    \"data_year-2\", \"data_year-3\",      # duplicate data_year\n",
    "\n",
    "    # Columns explicitly requested by user to be dropped\n",
    "    \"submission_date\",\n",
    "    \"arrest_type_code\",\n",
    "    \"cleared_except_date\",\n",
    "    \"cleared_except_id\",\n",
    "    \"did\",\n",
    "    \"age_id\",\n",
    "    \"age_range_low_num\",\n",
    "    \"age_range_high_num\",\n",
    "    \"arrestee_seq_num\",\n",
    "    \"offense_id\",\n",
    "    \"data_year\",\n",
    "    \"arrest_type_id\",\n",
    "\n",
    "    # Low-information or constant columns (dropped directly without verification)\n",
    "    \"report_date_flag\",\n",
    "    \"data_home\",\n",
    "    \"orig_format\",\n",
    "    \"ct_flag\",\n",
    "    \"hc_flag\",\n",
    "    \"hc_code\",\n",
    "    \"clearance_ind\",\n",
    "    \"resident_code\",\n",
    "    \"under_18_disposition_code\"\n",
    "]\n",
    "\n",
    "# 3. Drop columns (if they exist in the DataFrame)\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors=\"ignore\")\n",
    "\n",
    "# 4. Save the slimmed-down CSV file\n",
    "df.to_csv(\"merged_2023_no_redundant.csv\", index=False)\n",
    "\n",
    "print(\"All specified columns have been removed. File saved as merged_2023_no_redundant.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
